{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENBmkCdzIlMO",
        "outputId": "71677593-efbe-48b9-d4e9-ee6376ddee96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.0.348-py3-none-any.whl (2.0 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/2.0 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-core<0.1,>=0.0.12 (from langchain)\n",
            "  Downloading langchain_core-0.0.12-py3-none-any.whl (181 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1.0,>=0.0.63 (from langchain)\n",
            "  Downloading langsmith-0.0.69-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.1,>=0.0.12->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.1,>=0.0.12->langchain) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.1,>=0.0.12->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.1,>=0.0.12->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, langchain-core, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.6.3 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.348 langchain-core-0.0.12 langsmith-0.0.69 marshmallow-3.20.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2023.11.17)\n",
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n",
            "Collecting sentence_transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.35.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.16.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (3.8.1)\n",
            "Collecting sentencepiece (from sentence_transformers)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
            "Building wheels for collected packages: sentence_transformers\n",
            "  Building wheel for sentence_transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=9cbae73b9088f3e924f11f72a1e97ce6f659d66193a06a70a869a87ec23dad7a\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence_transformers\n",
            "Installing collected packages: sentencepiece, sentence_transformers\n",
            "Successfully installed sentence_transformers-2.2.2 sentencepiece-0.1.99\n"
          ]
        }
      ],
      "source": [
        "#Credits Janakiram MSV -contributor infoworld\n",
        "!pip install langchain\n",
        "!pip install huggingface_hub\n",
        "!pip install faiss-gpu\n",
        "!pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wFyj5qh_Ioe2"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import GooglePalm\n",
        "from langchain.embeddings import GooglePalmEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.chains.question_answering import load_qa_chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZyyBv2QVAUZ",
        "outputId": "31dd1436-1011-429a-d1e2-18ac7311e48e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conversion complete. Text data saved to 'auto_data.txt'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Replace 'your_file.xlsx' with the actual file path\n",
        "xlsx_file = '/content/Autograde_Dataset_Full.xlsx'\n",
        "\n",
        "# Read the Excel file into a Pandas DataFrame\n",
        "df = pd.read_excel(xlsx_file)\n",
        "\n",
        "# Replace 'output.txt' with the desired output text file name\n",
        "txt_file = 'auto_data.txt'\n",
        "\n",
        "# Save the DataFrame to a text file (tab-separated values)\n",
        "df.to_csv(txt_file, sep='\\t', index=False)\n",
        "\n",
        "print(f\"Conversion complete. Text data saved to '{txt_file}'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "jHkmlaGWIop0"
      },
      "outputs": [],
      "source": [
        "# loader = PyPDFLoader (\"/content/para_faculty_data.txt\")\n",
        "loader = TextLoader(\"/content/auto_data.txt\")\n",
        "documents = loader.load()\n",
        "\n",
        "# Convert the content into raw text.\n",
        "raw_text = ''\n",
        "for i, doc in enumerate(documents):\n",
        "    text = doc.page_content\n",
        "    if text:\n",
        "        raw_text += text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_dTOgwsIow4",
        "outputId": "4899f85a-2155-4eec-94af-457f813ced7f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain.text_splitter:Created a chunk of size 402, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 301, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 314, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 315, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 328, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 233, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 219, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 201, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 428, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 338, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 262, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 219, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 201, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 336, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 219, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 201, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 429, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 490, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 376, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 219, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 201, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 241, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 219, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 201, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 212, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 202, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 294, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 236, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 628, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 410, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 233, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 308, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 240, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 302, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 278, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 367, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 282, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 221, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 213, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 204, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 215, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 222, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 260, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 284, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 310, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 247, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 257, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 381, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 215, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 302, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 232, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 314, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 357, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 215, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 459, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 369, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 521, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 347, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 365, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 236, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 259, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 221, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 306, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 309, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 511, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 264, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 214, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 206, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 204, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 288, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 222, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 286, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 356, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 218, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 442, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 416, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 334, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 202, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 214, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 288, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 293, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 265, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 202, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 211, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 229, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 213, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 501, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 357, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 302, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 321, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 461, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 250, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 252, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 289, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 301, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 238, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 289, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 273, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 233, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 306, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 208, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 350, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 357, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 229, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 320, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 206, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 263, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 287, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 238, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 275, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 239, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 310, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 350, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 357, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 202, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 207, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 221, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 211, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 314, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 357, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 302, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 321, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 549, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 250, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 252, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 249, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 289, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 301, which is longer than the specified 200\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 228, which is longer than the specified 200\n"
          ]
        }
      ],
      "source": [
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\",\n",
        "    chunk_size = 200,\n",
        "    chunk_overlap  = 40,\n",
        "    length_function = len,\n",
        ")\n",
        "texts = text_splitter.split_text(raw_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoOOiaWGMKGR",
        "outputId": "5d8ecb66-4712-4916-d8c2-15e9dd2d707a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google.generativeai in /usr/local/lib/python3.10/dist-packages (0.2.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.3.3 in /usr/local/lib/python3.10/dist-packages (from google.generativeai) (0.3.3)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (from google.generativeai) (2.17.3)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google.generativeai) (2.11.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google.generativeai) (3.20.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google.generativeai) (4.66.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.3.3->google.generativeai) (1.22.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google.generativeai) (1.61.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google.generativeai) (2.31.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->google.generativeai) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth->google.generativeai) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->google.generativeai) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth->google.generativeai) (4.9)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google.generativeai) (1.59.3)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google.generativeai) (1.48.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth->google.generativeai) (0.5.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (2023.11.17)\n"
          ]
        }
      ],
      "source": [
        "! pip install google.generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XhpF1XU9MacL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4vtdQ4STLnkT"
      },
      "outputs": [],
      "source": [
        "my_api=\"AIzaSyDacJH5itizG-xyj4nHJRe6-L4PrdoLSuk\"\n",
        "import os\n",
        "\n",
        "# Set the GOOGLE_API_KEY environment variable\n",
        "os.environ[\"GOOGLE_API_KEY\"] = my_api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "n7flpnYeIo9t"
      },
      "outputs": [],
      "source": [
        "embeddings = GooglePalmEmbeddings()\n",
        "docsearch = FAISS.from_texts(texts, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "K4X_Rh1pJDOK"
      },
      "outputs": [],
      "source": [
        "chain = load_qa_chain(GooglePalm(), chain_type=\"stuff\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "IuHLPTqxoiS8",
        "outputId": "8608d933-7ae9-4367-d1c5-9dafcaece67e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7bba35f7-9606-4200-ae5b-d42d0b0e2e90\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Homework</th>\n",
              "      <th>Task</th>\n",
              "      <th>Task_Solution_Code</th>\n",
              "      <th>Task_Solution_Report</th>\n",
              "      <th>Task_Solution_Expectations</th>\n",
              "      <th>Task_Solution_Result_Points</th>\n",
              "      <th>Task_Solution_Result_Feedback</th>\n",
              "      <th>Reference_Feedback</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HW1</td>\n",
              "      <td>CS 590 NLP\\nHW1\\nRegular Expressions\\nDue 09/0...</td>\n",
              "      <td>def regex_stats(text_file):\\n    while True:\\n...</td>\n",
              "      <td>REGEX_STATS\\nSteps in finding each of the stat...</td>\n",
              "      <td>Homework Reports\\n\\nThings your report might i...</td>\n",
              "      <td>50.0</td>\n",
              "      <td>Overall Feedback\\nNice report!</td>\n",
              "      <td>The Report was good and all the desired files ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HW2</td>\n",
              "      <td>CS 590 NLP\\nHW2\\nText Normalization\\nDue 09/13...</td>\n",
              "      <td>def summarize_corpus(file_location):\\n    #imp...</td>\n",
              "      <td>summarize_corpus(file_location)\\n\\n• How the f...</td>\n",
              "      <td>Homework Reports\\n\\nThings your report might i...</td>\n",
              "      <td>50.0</td>\n",
              "      <td>Overall Feedback\\nNice report!</td>\n",
              "      <td>The Report had all the required data and expla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HW3</td>\n",
              "      <td>CS 590 NLP\\nHW3\\nLanguage Models\\nDue 09/25 11...</td>\n",
              "      <td>import pandas as pd #import pandas\\ndf=pd.read...</td>\n",
              "      <td>The methodology used to create your LMs. (NLTK...</td>\n",
              "      <td>Homework Reports\\n\\nThings your report might i...</td>\n",
              "      <td>48.0</td>\n",
              "      <td>Overall Feedback\\n-2 points (you were already ...</td>\n",
              "      <td>Please dont attach screenshot of output in rep...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HW4</td>\n",
              "      <td>CS 590 NLP\\nHW4\\nLogistic Regression\\nDue 10/0...</td>\n",
              "      <td>\\nimport pandas as pd #Pandas for dataframe\\nf...</td>\n",
              "      <td>• The methodology used to split the data\\n\\tI...</td>\n",
              "      <td>Homework Reports\\n\\nThings your report might i...</td>\n",
              "      <td>50.0</td>\n",
              "      <td>Overall Feedback\\nNice report!</td>\n",
              "      <td>Great Report all data is diaplayed and the acc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HW5</td>\n",
              "      <td>CS 590 NLP\\nHW5, Word2Vec\\nDue 10/30 11:59 pm\\...</td>\n",
              "      <td>import pandas as pd #pandas for datframe opera...</td>\n",
              "      <td>• The standard preprocessing used in all 4 met...</td>\n",
              "      <td>Homework Reports\\n\\nThings your report might i...</td>\n",
              "      <td>48.0</td>\n",
              "      <td>Overall Feedback\\n-2 (Report is missing discus...</td>\n",
              "      <td>Please try to add the missing part in  the rep...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7bba35f7-9606-4200-ae5b-d42d0b0e2e90')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7bba35f7-9606-4200-ae5b-d42d0b0e2e90 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7bba35f7-9606-4200-ae5b-d42d0b0e2e90');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7feb6780-010c-4548-8800-94edac300fde\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7feb6780-010c-4548-8800-94edac300fde')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7feb6780-010c-4548-8800-94edac300fde button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  Homework                                               Task  \\\n",
              "0      HW1  CS 590 NLP\\nHW1\\nRegular Expressions\\nDue 09/0...   \n",
              "1      HW2  CS 590 NLP\\nHW2\\nText Normalization\\nDue 09/13...   \n",
              "2      HW3  CS 590 NLP\\nHW3\\nLanguage Models\\nDue 09/25 11...   \n",
              "3      HW4  CS 590 NLP\\nHW4\\nLogistic Regression\\nDue 10/0...   \n",
              "4      HW5  CS 590 NLP\\nHW5, Word2Vec\\nDue 10/30 11:59 pm\\...   \n",
              "\n",
              "                                  Task_Solution_Code  \\\n",
              "0  def regex_stats(text_file):\\n    while True:\\n...   \n",
              "1  def summarize_corpus(file_location):\\n    #imp...   \n",
              "2  import pandas as pd #import pandas\\ndf=pd.read...   \n",
              "3  \\nimport pandas as pd #Pandas for dataframe\\nf...   \n",
              "4  import pandas as pd #pandas for datframe opera...   \n",
              "\n",
              "                                Task_Solution_Report  \\\n",
              "0  REGEX_STATS\\nSteps in finding each of the stat...   \n",
              "1  summarize_corpus(file_location)\\n\\n• How the f...   \n",
              "2  The methodology used to create your LMs. (NLTK...   \n",
              "3  • The methodology used to split the data\\n\\tI...   \n",
              "4  • The standard preprocessing used in all 4 met...   \n",
              "\n",
              "                          Task_Solution_Expectations  \\\n",
              "0  Homework Reports\\n\\nThings your report might i...   \n",
              "1  Homework Reports\\n\\nThings your report might i...   \n",
              "2  Homework Reports\\n\\nThings your report might i...   \n",
              "3  Homework Reports\\n\\nThings your report might i...   \n",
              "4  Homework Reports\\n\\nThings your report might i...   \n",
              "\n",
              "   Task_Solution_Result_Points  \\\n",
              "0                         50.0   \n",
              "1                         50.0   \n",
              "2                         48.0   \n",
              "3                         50.0   \n",
              "4                         48.0   \n",
              "\n",
              "                       Task_Solution_Result_Feedback  \\\n",
              "0                     Overall Feedback\\nNice report!   \n",
              "1                     Overall Feedback\\nNice report!   \n",
              "2  Overall Feedback\\n-2 points (you were already ...   \n",
              "3                     Overall Feedback\\nNice report!   \n",
              "4  Overall Feedback\\n-2 (Report is missing discus...   \n",
              "\n",
              "                                  Reference_Feedback  \n",
              "0  The Report was good and all the desired files ...  \n",
              "1  The Report had all the required data and expla...  \n",
              "2  Please dont attach screenshot of output in rep...  \n",
              "3  Great Report all data is diaplayed and the acc...  \n",
              "4  Please try to add the missing part in  the rep...  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "hSG3bweJp8uf",
        "outputId": "06d762fa-57e7-4e08-e432-b80afd22fae1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"CS 590 NLP\\nHW1\\nRegular Expressions\\nDue 09/04 11:59 pm\\nIn this homework, you will be creating two functions: 1) allows a user to enter a token (word) and\\nthen uses regular expressions to create stats about the token in the text, 2) allows a user to substitute\\nnew tokens for old tokens (via regular expressions).\\n>>> regex_stats(“warofworlds.txt”)\\nPlease enter a token to receive stats on (or quit to quit):the\\nNumber of unique matches: 4562\\nNumber of times the token occurs inside another word: 332\\nNumber of non-capitalized matches: 4562\\nNumber of capitalized matches: 350\\nPlease enter a token to receive stats on (or quit to quit):quit\\n>>> regex_substitute('waroftheworlds.txt', 'subbed_waroftheworlds.txt')\\nPlease enter a token to replace (or quit to quit):the\\nPlease enter a token to substitute:www\\nPlease enter a token to replace (or quit to quit):quit\\n>>> regex_stats('subbed_waroftheworlds.txt')\\nPlease enter a token to receive stats on (or quit to quit):the\\nNumber of unique matches: 0\\nNumber of times the token occurs inside another word: 332\\nNumber of non-capitalized matches: 0\\nNumber of capitalized matches: 350\\nPlease enter a token to receive stats on (or quit to quit):www\\nNumber of unique matches: 4562\\nNumber of times the token occurs inside another word: 0\\nNumber of non-capitalized matches: 4562\\nNumber of capitalized matches: 0\\nPlease enter a token to receive stats on (or quit to quit):quit\\n(Note the above numbers serve only as examples, your numbers may slightly differ).\\nregex_stats(filename)\\nYour goal with regex_stats should be to print out the following statistics about the entered token:\\n1. Number of unique matches\\n2. Number of times the token (or word) occurs withing another word.\\n- e.g. ‘the’ occurs inside ‘there’\\n3. Number of non-capitalized matches (e.g. ‘the’)\\n- note this is different from all lowercase\\n4. Number of capitalized matches (e.g. ‘The’)\\n- note this is different from all uppercase\\nCoding requirements\\n• You must use regular expressions in python to accomplish the above task. (re library)\\no Hint: re.search/re.findall\\n• You must not split the text into individual words (you will lose points if you do)\\n• Your function must take in a relative path to a filename and use the text from that file for\\nthe search.\\n• Your function should loop until the user enters “quit”\\nReport Requirements\\nInclude in your report document:\\n• Your steps in finding each of the statistics.\\no This should include your initial steps you tried, errors found, and how your\\nultimately came to your final algorithm.\\no (No code should be included) (You may reference line numbers in python file).\\n• The output for token ‘the’ in waroftheworlds.txt\\n• The output for token ‘tHE’ in waroftheworlds.txt\\n• The output for token ‘No’ in waroftheworlds.txt\\n• The output for token ‘Martians’ in waroftheworlds.txt\\n• Any surprises/difficulties encountered during the implementation.\\nregex_substitute(input_filename, output_filename)\\nYour goal with regex_substitute is to query the user for a search token and a replace token and\\nsubstitute all instances of the search token with the replace token in the input_file text. The resulting\\ntext should be written to the output_file.\\nCoding requirements\\n• You must use regular expressions in python to accomplish the above task. (re library)\\no Hint: re.sub\\n• You must not split the text into individual words (you will lose points if you do)\\n• Your function must take in a relative path to a filename and use the text from that file for\\nthe search and substitute.\\n• Your function should loop until the user enters “quit”, allowing multiple substitutions to be\\nmade.\\nReport Requirements\\nInclude in your report document:\\n• Your steps in making the substitutions.\\no This should include the initial steps you tried, errors found, and how your ultimately\\ncame to your final algorithm.\\no (No code should be included) (You may reference line numbers in python file).\\n• Substitute ‘the’ with ‘that’ in waroftheworlds.txt and provide sample lines of the\\nsubstitution.\\n• Substitute ‘me’ with ‘you’ in waroftheworlds.txt and provide sample lines of the\\nsubstitution.\\n• Errors/corrections made to your algorithm while executing the above experiments.\\nAdditional Rules (MUST BE FOLLOWED):\\n1. The code should be written in python 3.\\n2. The functions must follow the naming and number of arguments as demonstrated.\\n3. Standard libraries should only be used for this assignment, ie. I shouldn’t have to download\\nextra libraries to run your code.\\n4. For regex, you can use the “re” library (import re)\\n(https://www.w3schools.com/python/python_regex.asp)\\n5. For the regex step, you should only use regex to process the text. That means NO SPLITTING\\nTEXTS INTO SEPERATE WORDS DURING REGEX STEP! You should only be processing the texts by\\nusing the commands in the re python library (findall, search, sub). (Although regex has a split()\\noption, sub() and findall() are applied to the entire text and therefore are more efficient than\\nsplitting and then checking the regex against every separate text).\\na. Depending on how you read the file in, you may either read it in line by line or the entire\\ntext at once. Either choice is fine.\\n6. You should make your code modular to the different steps. (You may have more functions to\\nhelp your main functions)\\n7. You should only hand in one python file: USERNAME_HW1.py.\\na. I will be able to have my own copy of the text file, so YOU SHOULDN’T HAND IN THE\\nTEXT FILES.\\n8. You should be adding comments to document your code. If I can’t understand why you perform\\nan action, then I can’t credit you for performing that action.\\n9. The report should be readable and reference your code, without explicitly including code.\\n10. You should include your name and homework number in the comments at the beginning of the\\npython file.\\nReport\\nThe reports for the homeworks are necessary to communicate your learning and thinking through of the\\nmaterial. Examples of good reports can be found on brightspace under Homeworks/Examples/. Note\\nthat your report style may differ, but it is a good reference to start with.\\nGrading\\nAssignment will be graded as follows:\\nDescription Points\\nCode Runs 5\\nRegex_stat Implementation 10\\nRegex_substitute Implementation 10\\nRegex_stat report 10\\nRegex_substitute report 10\\nDocumentation/Code (Comments, functions, etc) 5\\nTotal: 50\\n- If the code does not run, I cannot grade it well. (More points than 5 can be lost if the code\\ncannot be run, as I will not be able to fully test the implementations of the other functions).\\n- Note that the example run provided may not be the exact numbers your receive. It is up to you\\nto decide if you are comfortable with the final results. In both research and industry you do not\\nalways have an exact final measurement to compare against.\\n- Breaking of the additional rules can result in applied penalties. (Always make sure you are\\nchecking against the rules)\\nSuggestions\\n- Documentation and a good report is key for showing your effort in this homework. Make sure\\nyou are noting why you make certain decisions throughout your code and report.\\n- The slides for previous classes are posted, so please refer to these and the book for ideas during\\nimplementation.\\n- Start simple, build up complexity. You should always make sure your new ideas being added do\\nnot cause your program to crash. So, starting simple is the best way to a) maintain the ability to\\nkeep your code running, b) add in comments for documentation and thought process as you add\\nmore code.\\n- Regexpal.com can be useful to test ideas for the regex step.\\n- Work through the homework yourself, rather than sharing ideas (especially not code) with other\\nstudents. As a reminder, plagiarism (or sharing) of code is strictly prohibited. This assignment\\nis complex enough that significant overlap between students will be suspicious.\\n- If you have not worked with python before, w3schools can help you translate your previous\\ncoding experience to python (https://www.w3schools.com/python/default.asp)\\n- Stop by office hours to discuss ideas. I am always happy to help you think through your process!\""
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"Task\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDzA9aiGyqTQ",
        "outputId": "6cd3fe56-b768-4259-df90-e821aee03158"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QSBkNdo0h_iF",
        "outputId": "ab062dfd-a2d9-4da9-a9d8-f3f7d41b1b8b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6455d6f3-ab1c-4497-b0cd-374807d0628b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Homework</th>\n",
              "      <th>Task</th>\n",
              "      <th>Task_Solution_Code</th>\n",
              "      <th>Task_Solution_Report</th>\n",
              "      <th>Task_Solution_Expectations</th>\n",
              "      <th>Task_Solution_Result_Points</th>\n",
              "      <th>Task_Solution_Result_Feedback</th>\n",
              "      <th>Reference_Feedback</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HW5</td>\n",
              "      <td>CS 590 NLP\\nHW5, Word2Vec\\nDue 10/30 11:59 pm\\...</td>\n",
              "      <td>import pandas as pd #pandas for datframe opera...</td>\n",
              "      <td>• The standard preprocessing used in all 4 met...</td>\n",
              "      <td>Homework Reports\\n\\nThings your report might i...</td>\n",
              "      <td>48.0</td>\n",
              "      <td>Overall Feedback\\n-2 (Report is missing discus...</td>\n",
              "      <td>Please try to add the missing part in  the rep...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>HW1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#Malia01\\n#hw1\\n#pwf_id=900399663\\n\\nimport re...</td>\n",
              "      <td>Hw1 – Regular Expressions Report\\n \\n \\n \\nreg...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>48.0</td>\n",
              "      <td>Overall Feedback\\n-2 points(regex_substitute()...</td>\n",
              "      <td>The code was missing a part of the assignment ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>HW2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#Malia01\\n#hw2\\n#pwf_id=900399663\\n\\nimport re...</td>\n",
              "      <td>Hw2 – Text Normalization Report\\n \\n \\n \\n \\ns...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>50.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The report was well structured and covered all...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>HW3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>import re\\nimport nltk\\nfrom nltk.util import ...</td>\n",
              "      <td>Hw3 –Language Model Training and Generation\\n ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>50.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>HW4\\n</td>\n",
              "      <td>NaN</td>\n",
              "      <td>import pandas as pd\\nfrom sklearn.model_select...</td>\n",
              "      <td>Hw4 –Logistic Regression\\n \\n \\nMethodology\\n ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>47.0</td>\n",
              "      <td>Overall Feedback\\n-4 points (The report is mis...</td>\n",
              "      <td>The report is missing the methodologies used t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>HW5</td>\n",
              "      <td>NaN</td>\n",
              "      <td># !pip install gensim\\nimport pandas as pd\\nfr...</td>\n",
              "      <td>Hw5 –Word Embeddings\\n \\n \\nPre-processing:\\n ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>50.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Great Report all data is diaplayed and the acc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>HW6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>import pandas as pd\\nfrom sklearn.model_select...</td>\n",
              "      <td>Hw6 – MLP’s\\n \\n \\nModels Description:\\n \\nAve...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>50.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The Report had all the required data and expla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>EC1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>from sklearn.feature_extraction.text import Co...</td>\n",
              "      <td>EC1 –Naïve Bayes\\n \\n \\nMethodology\\n \\nChosen...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Good Work!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>HW1</td>\n",
              "      <td>NaN</td>\n",
              "      <td># This is main program written by Ajinkya Shek...</td>\n",
              "      <td>REPORT ON REGEX IN PYTHON: TEXT ANALYSIS AND S...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>45.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>HW2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>import re\\n\\n\\n# Define a function to summariz...</td>\n",
              "      <td>REPORT ON NORMALIZING USING REGEX IN PYTHON: T...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>43.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>HW3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>##########CODE IS WORKING CORRECTLY AND WAS TR...</td>\n",
              "      <td>REPORT ON LM USING NLTK IN PYTHON: MODEL TRAIN...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>50.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The Report had all the required data and expla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>HW4\\n</td>\n",
              "      <td>NaN</td>\n",
              "      <td>import numpy as np\\nimport pandas as pd\\nfrom ...</td>\n",
              "      <td>REPORT ON SCIKITLEARN LIBRARY TO PERFORM LOGIS...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>50.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Good Work!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>HW5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>import numpy as np\\nimport pandas as pd\\nfrom ...</td>\n",
              "      <td>REPORT ON WORD2VECT PRETRAINED MODELS AND ITS ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>48.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>HW6</td>\n",
              "      <td>NaN</td>\n",
              "      <td># -*- coding: utf-8 -*-\\n\"\"\"mlp_sentiment_pred...</td>\n",
              "      <td>REPORT ON WORD2VECT PRETRAINED MODELS AND ITS ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>48.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>EC1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>import numpy as np\\nimport pandas as pd\\nfrom ...</td>\n",
              "      <td>REPORT ON SCIKITLEARN LIBRARY TO PERFORM LOGIS...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6455d6f3-ab1c-4497-b0cd-374807d0628b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6455d6f3-ab1c-4497-b0cd-374807d0628b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6455d6f3-ab1c-4497-b0cd-374807d0628b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-800178e3-a479-45fb-895e-ffaff0f03a1c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-800178e3-a479-45fb-895e-ffaff0f03a1c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-800178e3-a479-45fb-895e-ffaff0f03a1c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   Homework                                               Task  \\\n",
              "4       HW5  CS 590 NLP\\nHW5, Word2Vec\\nDue 10/30 11:59 pm\\...   \n",
              "5       HW1                                                NaN   \n",
              "6       HW2                                                NaN   \n",
              "7       HW3                                                NaN   \n",
              "8     HW4\\n                                                NaN   \n",
              "9       HW5                                                NaN   \n",
              "10      HW6                                                NaN   \n",
              "11      EC1                                                NaN   \n",
              "12      HW1                                                NaN   \n",
              "13      HW2                                                NaN   \n",
              "14      HW3                                                NaN   \n",
              "15    HW4\\n                                                NaN   \n",
              "16      HW5                                                NaN   \n",
              "17      HW6                                                NaN   \n",
              "18      EC1                                                NaN   \n",
              "\n",
              "                                   Task_Solution_Code  \\\n",
              "4   import pandas as pd #pandas for datframe opera...   \n",
              "5   #Malia01\\n#hw1\\n#pwf_id=900399663\\n\\nimport re...   \n",
              "6   #Malia01\\n#hw2\\n#pwf_id=900399663\\n\\nimport re...   \n",
              "7   import re\\nimport nltk\\nfrom nltk.util import ...   \n",
              "8   import pandas as pd\\nfrom sklearn.model_select...   \n",
              "9   # !pip install gensim\\nimport pandas as pd\\nfr...   \n",
              "10  import pandas as pd\\nfrom sklearn.model_select...   \n",
              "11  from sklearn.feature_extraction.text import Co...   \n",
              "12  # This is main program written by Ajinkya Shek...   \n",
              "13  import re\\n\\n\\n# Define a function to summariz...   \n",
              "14  ##########CODE IS WORKING CORRECTLY AND WAS TR...   \n",
              "15  import numpy as np\\nimport pandas as pd\\nfrom ...   \n",
              "16  import numpy as np\\nimport pandas as pd\\nfrom ...   \n",
              "17  # -*- coding: utf-8 -*-\\n\"\"\"mlp_sentiment_pred...   \n",
              "18  import numpy as np\\nimport pandas as pd\\nfrom ...   \n",
              "\n",
              "                                 Task_Solution_Report  \\\n",
              "4   • The standard preprocessing used in all 4 met...   \n",
              "5   Hw1 – Regular Expressions Report\\n \\n \\n \\nreg...   \n",
              "6   Hw2 – Text Normalization Report\\n \\n \\n \\n \\ns...   \n",
              "7   Hw3 –Language Model Training and Generation\\n ...   \n",
              "8   Hw4 –Logistic Regression\\n \\n \\nMethodology\\n ...   \n",
              "9   Hw5 –Word Embeddings\\n \\n \\nPre-processing:\\n ...   \n",
              "10  Hw6 – MLP’s\\n \\n \\nModels Description:\\n \\nAve...   \n",
              "11  EC1 –Naïve Bayes\\n \\n \\nMethodology\\n \\nChosen...   \n",
              "12  REPORT ON REGEX IN PYTHON: TEXT ANALYSIS AND S...   \n",
              "13  REPORT ON NORMALIZING USING REGEX IN PYTHON: T...   \n",
              "14  REPORT ON LM USING NLTK IN PYTHON: MODEL TRAIN...   \n",
              "15  REPORT ON SCIKITLEARN LIBRARY TO PERFORM LOGIS...   \n",
              "16  REPORT ON WORD2VECT PRETRAINED MODELS AND ITS ...   \n",
              "17  REPORT ON WORD2VECT PRETRAINED MODELS AND ITS ...   \n",
              "18  REPORT ON SCIKITLEARN LIBRARY TO PERFORM LOGIS...   \n",
              "\n",
              "                           Task_Solution_Expectations  \\\n",
              "4   Homework Reports\\n\\nThings your report might i...   \n",
              "5                                                 NaN   \n",
              "6                                                 NaN   \n",
              "7                                                 NaN   \n",
              "8                                                 NaN   \n",
              "9                                                 NaN   \n",
              "10                                                NaN   \n",
              "11                                                NaN   \n",
              "12                                                NaN   \n",
              "13                                                NaN   \n",
              "14                                                NaN   \n",
              "15                                                NaN   \n",
              "16                                                NaN   \n",
              "17                                                NaN   \n",
              "18                                                NaN   \n",
              "\n",
              "    Task_Solution_Result_Points  \\\n",
              "4                          48.0   \n",
              "5                          48.0   \n",
              "6                          50.0   \n",
              "7                          50.0   \n",
              "8                          47.0   \n",
              "9                          50.0   \n",
              "10                         50.0   \n",
              "11                         20.0   \n",
              "12                         45.0   \n",
              "13                         43.0   \n",
              "14                         50.0   \n",
              "15                         50.0   \n",
              "16                         48.0   \n",
              "17                         48.5   \n",
              "18                         15.5   \n",
              "\n",
              "                        Task_Solution_Result_Feedback  \\\n",
              "4   Overall Feedback\\n-2 (Report is missing discus...   \n",
              "5   Overall Feedback\\n-2 points(regex_substitute()...   \n",
              "6                                                 NaN   \n",
              "7                                                 NaN   \n",
              "8   Overall Feedback\\n-4 points (The report is mis...   \n",
              "9                                                 NaN   \n",
              "10                                                NaN   \n",
              "11                                                NaN   \n",
              "12                                                NaN   \n",
              "13                                                NaN   \n",
              "14                                                NaN   \n",
              "15                                                NaN   \n",
              "16                                                NaN   \n",
              "17                                                NaN   \n",
              "18                                                NaN   \n",
              "\n",
              "                                   Reference_Feedback  \n",
              "4   Please try to add the missing part in  the rep...  \n",
              "5   The code was missing a part of the assignment ...  \n",
              "6   The report was well structured and covered all...  \n",
              "7                                                 NaN  \n",
              "8   The report is missing the methodologies used t...  \n",
              "9   Great Report all data is diaplayed and the acc...  \n",
              "10  The Report had all the required data and expla...  \n",
              "11                                         Good Work!  \n",
              "12                                                NaN  \n",
              "13                                                NaN  \n",
              "14  The Report had all the required data and expla...  \n",
              "15                                         Good Work!  \n",
              "16                                                NaN  \n",
              "17                                                NaN  \n",
              "18                                                NaN  "
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.tail(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iY3nOUyjvhCP",
        "outputId": "3ceafeea-81d4-4efc-c4e0-4b05964e0dde"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Task:  Task_Solution_Result_Points: 40\n",
            "Task_Solution_Result_Feedback: Good work! Your code is well-structured and easy to understand. Some minor comments:\n",
            "- In your regex_stats function, you can use the linecache module to avoid reading the entire file into memory.\n",
            "- In your regex_substitute function, you can use the linecache module to avoid writing the entire file to disk.\n",
            "- In your code, you use the variable \"tokens\" to store the output of the regex_stats function. It would be better to use a more descriptive name, such as \"token_counts\".\n",
            "- In your regex_substitute function, you use the variable \"input_file\" to store the path to the input file. It would be better to use a more descriptive name, such as \"input_filepath\".\n",
            "- In your regex_substitute function, you use the variable \"output_file\" to store the path to the output file. It would be better to use a more descriptive name, such as \"output_filepath\".\n",
            "BLEU Score: 6.2651549018314805e-232\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Task:  Task_Solution_Result_Points: 40\n",
            "Task_Solution_Result_Feedback: Good work! It seems like you have a good understanding of the concepts. Keep up the good work!\n",
            "BLEU Score: 8.844844403089351e-232\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Task:  Task_Solution_Result_Points: 45\n",
            "Task_Solution_Result_Feedback: Good job.\n",
            "\n",
            "The student used NLTK to create the LMs. They also described the process used to set up and train the LMs. They encountered a problem with reading the data from the dataframe, but they were able to resolve the issue. The student generated text for all 3 LMs with 3 different prompts. They also made some observations on the generated texts. Overall, the student did a good job on this task.\n",
            "BLEU Score: 7.411994825316195e-232\n",
            "\n",
            "\n",
            "Task:  Task_Solution_Result_Points: 40\n",
            "Task_Solution_Result_Feedback: Good work! The model is performing well on both the class labels. Some improvements can be made by increasing the number of features, reducing the regularization strength, and setting the class weight to balanced.\n",
            "BLEU Score: 0\n",
            "\n",
            "\n",
            "\n",
            " Skipping \n",
            "\n",
            "No response found.\n",
            "No response found.\n",
            "No response found.\n",
            "Task:  Task_Solution_Result_Points: 40\n",
            "Task_Solution_Result_Feedback: Good work! Some minor points for improvement:\n",
            "- Add more details about the dataset and the pre-processing steps.\n",
            "- Explain why you chose to use TF-IDF vectorizer and logistic regression.\n",
            "- Discuss the pros and cons of your approach.\n",
            "- Provide more insights into the results (e.g., why does the accuracy decrease as the test percentage increases?).\n",
            "BLEU Score: 0\n",
            "\n",
            "\n",
            "Task:  Task_Solution_Result_Points: 35\n",
            "Task_Solution_Result_Feedback: Good job! I see that you have implemented the following:\n",
            "- Pre-processing steps (lowercasing, punctuation removal, tokenization, stopword removal)\n",
            "- 2 different kinds of word embeddings (Google News Word2Vec and FastText)\n",
            "- Weighted IDF weight averaging\n",
            "- N-grams\n",
            "- Evaluation and future work\n",
            "Some areas for improvement include:\n",
            "- Your code is not very well-organized. It would be helpful to break it up into separate functions and/or classes.\n",
            "- You could provide more details about your implementation. For example, how did you choose the parameters for your model?\n",
            "- You could also include more results and analysis.\n",
            "BLEU Score: 0\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Task:  Task_Solution_Result_Points: 45\n",
            "Task_Solution_Result_Feedback: Great work! Your code is well-written and your report is clear and concise. You did a good job of analyzing the different approaches and providing a thoughtful conclusion.\n",
            "BLEU Score: 9.418382295637229e-232\n",
            "\n",
            "\n",
            "Task:  Task_Solution_Result_Points: 30\n",
            "Task_Solution_Result_Feedback: Good job! You correctly implemented the Naive Bayes model and analyzed its performance. You could improve by providing more detailed explanations of your results and by discussing potential areas for improvement.\n",
            "BLEU Score: 0\n",
            "\n",
            "\n",
            "No response found.\n",
            "No response found.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Task:  Task_Solution_Result_Points: 40\n",
            "Task_Solution_Result_Feedback: Good work. \n",
            "\n",
            "Although the report is a bit long, it is well-written and easy to follow. The code is also well-organized and commented, which makes it easy to understand.\n",
            "\n",
            "There are a few things that could be improved, however. First, the report could be more concise. For example, the section on the LM_generate function could be shortened by combining some of the steps. Second, the code could be more efficient. For example, the section on tokenizing the input could be improved by using a more efficient algorithm.\n",
            "\n",
            "Overall, however, this is a good piece of work.\n",
            "BLEU Score: 6.921464794211712e-232\n",
            "\n",
            "\n",
            "No response found.\n",
            "No response found.\n",
            "No response found.\n",
            "No response found.\n"
          ]
        }
      ],
      "source": [
        "scores=[]\n",
        "original_scores=[]\n",
        "bleu_scores=[]\n",
        "for i in range(0,len(df)):\n",
        "    user_code= df[\"Task_Solution_Code\"][i]\n",
        "    user_report=df[\"Task_Solution_Report\"][i]\n",
        "    task=df[\"Task\"][i]\n",
        "    query_template = \"What should be the Task_Solution_Result_Points(out of 50)(scoring should be generous) and Task_Solution_Result_Feedback(upto 25 words) for the student with the given code and report. Feedback should be more critical as Task_Result_Solution_Points decrease.\"\n",
        "\n",
        "    # Create separate queries\n",
        "    query_for_task = f\"{query_template} Task Description: {task}\"\n",
        "    query_for_code = f\"{query_template} Solution Code: {user_code} \"\n",
        "    query_for_report = f\"{query_template} Solution Report: {user_report}\"\n",
        "    # Process each query separately\n",
        "    try:\n",
        "        if len(query_for_task)>10000 or len(query_for_code)>10000 or len(query_for_report)>10000:\n",
        "          print(\"\\n Skipping \\n\")\n",
        "          continue\n",
        "        docs_task = docsearch.similarity_search(query_for_task)\n",
        "        result_task = chain.run(input_documents=docs_task, question=query_for_task).strip()\n",
        "\n",
        "        docs_code = docsearch.similarity_search(query_for_code)\n",
        "        code_result = chain.run(input_documents=docs_code, question=query_for_code).strip()\n",
        "\n",
        "        docs_report=docsearch.similarity_search(query_for_report)\n",
        "\n",
        "        result=chain.run(input_documents=docs_report, question=query_for_report).strip()\n",
        "\n",
        "        # Combine results from each part (you can modify this as per your requirement)\n",
        "        combined_result = f\"Task:  {result}\"\n",
        "        feedback=combined_result.split(\"Task_Solution_Result_Feedback:\")[1]\n",
        "        score=combined_result.split(\"Task_Solution_Result_Feedback:\")[0].split(\" \")[-1]\n",
        "        bleu_score = sentence_bleu( df[\"Reference_Feedback\"][i].split() , feedback.split())\n",
        "        scores.append(score)\n",
        "        bleu_scores.append(bleu_score)\n",
        "        original_scores.append(int(df[\"Task_Solution_Result_Points\"][i]))\n",
        "        print(combined_result)\n",
        "        print(f\"BLEU Score: {bleu_score}\")\n",
        "        print(\"\\n\")\n",
        "    except (IndexError, AttributeError):\n",
        "        print(\"No response found.\")\n",
        "    i+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaggNYt3gGNn",
        "outputId": "4d5ba45d-68e0-4a75-b09e-db0ad6503634"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['40\\n', '40\\n', '45\\n', '40\\n', '40\\n', '35\\n', '45\\n', '30\\n', '40\\n']"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVP6K9WsgN20",
        "outputId": "8f16445d-d219-49c4-b14a-fa0162d18b97"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[6.2651549018314805e-232,\n",
              " 8.844844403089351e-232,\n",
              " 7.411994825316195e-232,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 9.418382295637229e-232,\n",
              " 0,\n",
              " 6.921464794211712e-232]"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bleu_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxmOzyD5lZa0",
        "outputId": "271e7a5e-c9c0-41f5-87e9-3b551f8a8865"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[50, 50, 48, 50, 47, 50, 50, 20, 50]"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "original_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "qgWhqJw0jjbT"
      },
      "outputs": [],
      "source": [
        "def convert_to_int(string):\n",
        "    # Remove newline characters and other non-numeric characters\n",
        "    cleaned_string = ''.join(filter(str.isdigit, string))\n",
        "    return int(cleaned_string)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imc5LMaKisUL",
        "outputId": "22753773-c970-4644-8f60-8640c44df8eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE: 89.77777777777777\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "y_true=original_scores\n",
        "y_pred = [convert_to_int(score) for score in scores]\n",
        "\n",
        "mse = mean_squared_error(y_true, y_pred)\n",
        "print(f\"MSE: {mse}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uhSfb5rgquo",
        "outputId": "536bc1fa-e1ec-4365-a03a-750059e094cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your code (type 'exit' to stop): import pandas as pd #dataframe ops import numpy as np #numerical ops from sklearn.model_selection import train_test_split #For splitting data into train and test set from sklearn.neural_network import MLPClassifier #multilayer perceptron for sentiment classification from sklearn.preprocessing import LabelEncoder #encoding sentiment to number from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix #test metrics import gensim # pretrained embeddings import gensim.downloader #download the embedding  # Load your pretrained Word2Vec or GloVe model model=gensim.downloader.load('word2vec-google-news-300') # downloading googles word2vec embedding  # Define a function to split the data into train and test sets def split_data(path_to_data_file, test_percentage): # 2 parameters- data file path and percentage of data to be taken for testing     data = pd.read_csv(path_to_data_file,encoding='utf-8') # reading file     train, test = train_test_split(data, test_size=test_percentage/100, stratify=data['sentiment']) # for splitting     #in train test. random_state sets seed to a value to control randomness and stratify ensures that samples from both class label are taken     # proportionally to avoid class imbalance in train and test data.     train_file_name = f\"train_{path_to_data_file.split('.')[0]}_{test_percentage}.csv\" #naming train data     test_file_name = f\"test_{path_to_data_file.split('.')[0]}_{test_percentage}.csv\"   # naming test data      train.to_csv(train_file_name, index=False) # write train file to csv     test.to_csv(test_file_name, index=False) # write test file to csv  split_data(\"IMDB_Dataset.csv\",20) #split train-80%,test-20%  # Load the IMDB dataset from a CSV file def load_imdb_dataset(path_to_dataset):     df = pd.read_csv(path_to_dataset) #read file     X = df['review'] #extract feature     y = df['sentiment']  # extract target     return X, y  # Train a multi-layer perceptron model using average embeddings def train_MLP_model_average(path_to_train_file):     # Load the IMDB dataset     X, y = load_imdb_dataset(path_to_train_file) #calling above function to get feature and target      # Encode labels (positive/negative) to numerical values (0/1)     label_encoder = LabelEncoder()#initialize     y = label_encoder.fit_transform(y)#transform target      # Load pre-trained Word2Vec embeddings (You need to download this)     word2vec_model = model #just renaming downloaded model to remember the model used is Word2vec      # Preprocess the text and compute average embeddings     def average_word_embeddings(text):         words = text.split() #text split based on space         embeddings = [word2vec_model[word] for word in words if word in word2vec_model] #if the word in the review has corresponding         # vector embedding in the model retrieve that embedding         if len(embeddings) > 0:             return np.mean(embeddings, axis=0) #average the embeddings         else:             return np.zeros(word2vec_model.vector_size) # if no embeddings found(to avert error)      X_avg = np.array([average_word_embeddings(text) for text in X]) #calling the function to average the embeddings      # Create and train the MLP model     mlp_model = MLPClassifier(hidden_layer_sizes=(100, 100, 100), max_iter=1000, random_state=42) # multi layer perceptron with 3 layers     # and 100 neurons in each layer     mlp_model.fit(X_avg, y) #fitting to the training data      return mlp_model\n",
            "Enter your report: Hypothetical reasoning behind the performance of the best model.  It appears that even though the best model is the “Average” MLP model, yet averaging the embeddings and adding them up both lead to almost similar results. However, the model that chooses “maximum” of the embeddings performs poorly. This is because choosing the maximum of the vector embeddings leads to loss of information of all the other vectors whereas, summing and averaging the embeddings incorporates the information from all the vectors thereby minimizing information loss.\n",
            "Enter the given task: Coding Requirements • Your functions should have the same name and number of arguments as noted above. • The function should fine-tune existing pretrained embeddings, not train brand new ones. • Good documentation is always required for understanding code. Make sure to include explanations (comments) of coding steps. • You may use either the “student” or “average” MLP model training, but you should note which you use and stay consistent for comparisons.\n",
            "40, Code is correct and well documented. Good work on the explanation of the results.\n",
            "Enter your code (type 'exit' to stop): exit\n",
            "Exiting the loop. Goodbye!\n"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "    # Prompt the user for code\n",
        "    user_code = input(\"Enter your code (type 'exit' to stop): \")\n",
        "\n",
        "    # Check if the user wants to exit\n",
        "    if user_code.lower() == 'exit':\n",
        "        print(\"Exiting the loop. Goodbye!\")\n",
        "        break\n",
        "\n",
        "    # Prompt the user for the report\n",
        "    user_report = input(\"Enter your report: \")\n",
        "    task=input(\"Enter the given task: \")\n",
        "\n",
        "    # Construct the query using a fixed template\n",
        "    query_template = \"What should be the Task_Solution_Result_Points(out of 50) and Task_Solution_Result_Feedback(upto 25 words) for the student with the given code and report. Feedback should be more critical as Task_Result_Solution_Points decrease \"\n",
        "    full_query = f\"{query_template}{task}{user_code} {user_report}\"\n",
        "\n",
        "    docs = docsearch.similarity_search(full_query)\n",
        "\n",
        "    try:\n",
        "        result = chain.run(input_documents=docs,question=full_query).strip()\n",
        "        print(result)\n",
        "    except (IndexError, AttributeError):\n",
        "        print(\"No response found.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jd4UNShPJDn6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3nVnwN7JD10"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
